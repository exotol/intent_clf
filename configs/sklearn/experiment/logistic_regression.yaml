# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: rtk
  - override /model: logistic_regression
  - override /checkpoints: local
  - override /logger: wandb
  - override /data_transformer: pipeline_cnt

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs

name: "log_reg_multiclass_prep_razdel_tfidf_char_wb_n_gram_1_7"

train: True

optimized_metric: "precision"
metric_aggregation: "micro"

print_config: True
ignore_warnings: False

seed: 12345
#trainer:
#  min_epochs: 10
#  max_epochs: 10
#  gradient_clip_val: 0.5
#
model:
  _target_: sklearn.linear_model.LogisticRegression
  multi_class: "multinomial"

data_transformer:
  _target_: rtk_mult_clf.make_pipeline

  steps_config: # use yaml list syntax to preserve to order
    - TextPreprocessTransformer:
        _target_: rtk_mult_clf.TextPreprocessTransformerDF
        column_name: "text"

    - TfIdfTransformer:
        _target_: rtk_mult_clf.TfIdfVectorizerDF
        column_name: "text"
        ngram_range: ${as_tuple:1,7}
        analyzer: "char_wb"
